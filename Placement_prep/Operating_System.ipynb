{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Operating System\n",
    "\n",
    "#### An operating system acts as an intermediary between the user of a computer and computer hardware. The purpose of an operating system is to provide an environment in which a user can execute programs conveniently and efficiently. \n",
    "\n",
    "####  An operating system is software that manages computer hardware. The hardware must provide appropriate mechanisms to ensure the correct operation of the computer system and to prevent user programs from interfering with the proper operation of the system.\n",
    "\n",
    "## Features of OS\n",
    "\n",
    "#### 1. Convenience\n",
    "#### 2. Efficiency\n",
    "#### 3. Ability to evolve and control system resources\n",
    "#### 4. Ability to handle multiprogramming and multiprocessing\n",
    "\n",
    "## Functions of OS\n",
    "\n",
    "#### 1. Process Management\n",
    "#### 2. Memory Management\n",
    "#### 3. File Management\n",
    "#### 4. Device Management (IO)\n",
    "#### 5. Protection and Security\n",
    "#### 6. Networking\n",
    "#### 7. Error Detection and Recovery\n",
    "\n",
    "## Types of OS\n",
    "\n",
    "#### 1. Batch Operating System  -> similar jobs are grouped together into batches with the help of some operator and these batches are executed one by one.\n",
    "#### 2. Time Sharing Operating System -> more than one processes are being executed at a particular time with the help of the time-sharing concept using time quantum.\n",
    "#### 3. Real Time Operating System ->  used in the situation where we are dealing with some real-time data , and there should be no dealy i.e. no buffer delays should be there.\n",
    "#### 4. Distributed Operating System -> have various systems and all these systems have their own resources and they are connected to each other through a network.\n",
    "#### 5. Embedded Operating System -> used in embedded systems like mobile phones, cars, etc. , Embedded Operating System is designed to perform a specific task for a particular device which is not a computer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernal\n",
    "\n",
    "#### kernel is the core part of an operating system. It manages the tasks of the computer and the hardware - most notably memory and CPU time.\n",
    "\n",
    "#### A computer user never interacts directly with the kernel. It runs behind the scenes and cannot be seen.\n",
    "#### Kernel is the most fundamental part of operating system it can be thought as program which controls all other programs.\n",
    "\n",
    "## Kernal Functions\n",
    "\n",
    "#### 1. Resource Allocation: - to manage the computer’s resource and allow other programs to run and use these resources.\n",
    "\n",
    "#### 2. Process Management: - allow the execution of application.\n",
    "\n",
    "#### 3. Memory Management: - allow process to access the memory which is require to run the process\n",
    "\n",
    "#### 4. Disk Management: - for creating, deleting, formatting partition etc…\n",
    "\n",
    "#### 5. I/O Device Management: - maintains list of available devices and provides I/O to physically access this device through some port or memory location.\n",
    "\n",
    "#### 6. Security or Protection management: -provide security from faults and from malicious behaviors.\n",
    "\n",
    "## Types of Kernal\n",
    "### A microkernel, which only contains basic functionality. seperate address space for each process , complex but small and fast , e.g. MAC OS X\n",
    "### A monolithic kernel, which contains many drivers. single address space for all processes , simple but large and slow , e.g. Windows 95 \n",
    "### A hybrid kernel, which contains both microkernel and monolithic kernel. e.g. Windows NT\n",
    "\n",
    "\n",
    "## Kernal vs OS\n",
    "\n",
    "#### An operating system is one of the most important components that helps in managing computer software and hardware resources. But Kernel is a core element of the OS that converts the user query into the machine language. OS provides an interface between hardware and user And Kernal provides an interface between application and hardware"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Virtual Memory\n",
    "\n",
    "#### Virtual memory is a memory management technique that allows a computer to use a portion of its hard disk as if it were RAM. It is a method of extending a computer's physical memory by using a portion of the hard disk as virtual memory.\n",
    "####  In Microprocessor , Virtual Memory is a computer concept where the main memory is broken up into a series of individual pages. Each page is a fixed size and is assigned a unique page number. The page number is used to access the page in memory. The page number is stored in the page table. The page table is a table of page numbers and their corresponding physical memory addresses. The page table is stored in the main memory. The page table is used to translate the page number into a physical memory address. The page table is stored in the main memory. The page table is used to translate the page number into a physical memory address.\n",
    "\n",
    "# Paging\n",
    "\n",
    "#### Paging is a memory management scheme by which the OS can make a physical address for each page in the virtual address space. The OS uses a page table to keep track of the mapping between the virtual and physical addresses. The page table is stored in main memory. The page table is used to translate the page number into a physical memory address. The page table is stored in the main memory. The page table is used to translate the page number into a physical memory address.\n",
    "\n",
    "# Segmentation\n",
    "\n",
    "#### Segmentation is a memory management technique in which each job is divided into several segments of different sizes, one for each module that contains pieces that perform related functions. Each segment is actually a different logical address space of the program.\n",
    "\n",
    "## Paging vs Segmentation\n",
    "\n",
    "#### In paging, the program is divided into fixed or mounted size pages but In segmentation, the program is divided into variable size sections.\n",
    "#### in paging , Page size is determined by hardware.\tbut in segmentation the section size is given by the user\n",
    "#### Paging could result in internal fragmentation And Segmentation could result in external fragmentation.\n",
    "#### Paging is invisible to the user.\tSegmentation is visible to the user.\n",
    "\n",
    "## Bootstrap programs\n",
    "\n",
    "#### A bootstrap program is the first code that is executed when the computer system is started. The entire operating system depends on the bootstrap program to work correctly as it loads the operating system. \n",
    "\n",
    "## Cache memory\n",
    "\n",
    "#### Cache memory is a chip-based computer component that makes retrieving data from the computer's memory more efficient. It acts as a temporary storage area that the computer's processor can retrieve data from easily."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Program\n",
    "\n",
    "### Program contains a set of instructions designed to complete a specific task. Program is a passive entity as it resides in the secondary memory\n",
    "\n",
    "# Process\n",
    "\n",
    "### Process is an instance of an executing program.Process is a active entity as it is created during execution and loaded into the main memory. Process has its own control block called Process Control Block. Dyanamic entity as it is created during execution and destroyed after execution.\n",
    "\n",
    "### PCB(Process Control Block) is a data structure that contains information about a process. It is used by the kernel to keep track of processes. It contains information such as the process state, the process priority, CPU registers, CPU scheduling information, memory management information, accounting information, I/O status information, and other information needed to manage the process.\n",
    "\n",
    "## State of a process\n",
    "\n",
    "### NEW: A new process is being created.\n",
    "### READY: A process is ready and waiting to be allocated to a processor.\n",
    "### RUNNING: The program is being executed.\n",
    "### WAITING: Waiting for some event to happen or occur.\n",
    "### TERMINATED: Execution finished.\n",
    "\n",
    "# Thread\n",
    "\n",
    "### A thread is the subset of a process and is also known as the lightweight process. A process can have more than one thread, and these threads are managed independently by the scheduler. All the threads within one process are interrelated to each other. Threads have some common information, such as data segment, code segment, files, etc., that is shared to their peer threads. But contains its own registers, stack, and counter.\n",
    "\n",
    "## Types of threads\n",
    "### 1. User level threads : User level threads are managed by the user-level library and the kernel does not have its information. faster, easy to create and manage.kernel takes all these threads as a single process and handles them as one process only.  implemented by user-level libraries, not by the system calls.\n",
    "\n",
    "### 2. Kernel level threads :  handled by the Operating system and managed by its kernel. These threads are slower than user-level threads because context information is managed by the kernel. To create and implement a kernel-level thread, we need to make a system call.\n",
    "\n",
    "## process vs thread \n",
    "\n",
    "### A process is independent and does not contained within another process, whereas all threads are logically contained within a process.\n",
    "### Processes are heavily weighted, whereas threads are light-weighted.\n",
    "### A process can exist individually as it contains its own memory and other resources, whereas a thread cannot have its individual existence.\n",
    "### A proper synchronization between processes is not required. In contrast, threads need to be synchronized in order to avoid unexpected scenarios.\n",
    "### Processes can communicate with each other using inter-process communication only; in contrast, threads can directly communicate with each other as they share the same address space.\n",
    "\n",
    "\n",
    "## Multitasking\n",
    "#### a single resource is used to process multiple tasks. follows the concept of context switching.\n",
    "\n",
    "## Multiprocessing\n",
    "#### In multiprocessing, multiple processing units are used by a single device. A large amount of work can be done in a short period of time.\n",
    "\n",
    "## Multithreading \n",
    "#### Multithreading is an extended form of multitasking. allows a single process to get multiple code segments.\n",
    "\n",
    "## Multiprogramming\n",
    "#### In multiprogramming, multiple programs execute at a same time on a single device.  processing is slower, as a single job resides in the main memory while execution.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process scheduling\n",
    "\n",
    "### Process scheduling is the activity of the process manager that handles the removal of the running process from the CPU and the selection of another process on the basis of a particular strategy.\n",
    "\n",
    "## There are two types of scheduling algorithms\n",
    "\n",
    "## 1. Preemptive scheduling\n",
    "### tasks are mostly assigned with their priorities. Sometimes it is important to run a task with a higher priority before another lower priority task, even if the lower priority task is still running. At that time, the lower priority task holds for some time and resumes when the higher priority task finishes its execution.\n",
    "\n",
    "## 2. Non-preemptive scheduling\n",
    "###  switching of resources occurs only when the running process terminates and moves to a waiting state.\n",
    "### it doesn’t need specialized hardware (for example, a timer) like preemptive Scheduling.\n",
    "\n",
    "## Scheduler \n",
    "### Schedulers are special system software which handle process scheduling in various ways. Their main task is to select the jobs to be submitted into the system and to decide which process to run. \n",
    "\n",
    "## Types of schedulers\n",
    "\n",
    "### 1. Long-term scheduler  ( job scheduler)\n",
    "#### determines which programs are admitted to the system for processing. It selects processes from the queue and loads them into memory for execution. Process loads into the memory for CPU scheduling.\n",
    "### 2. Short-term scheduler  (CPU scheduler)\n",
    "####  It is the change of ready state to running state of the process. CPU scheduler selects a process among the processes that are ready to execute and allocates CPU to one of them.\n",
    "### 3. Medium-term scheduler (Swapper)\n",
    "#### It removes the processes from the memory. It reduces the degree of multiprogramming. The medium-term scheduler is in-charge of handling the swapped out-processes.\n",
    "\n",
    "\n",
    "\n",
    "### Zombie Process\n",
    "#### it is a process that has completed execution (via the exit system call) but still has an entry in the process table: it is a process in the \"Terminated state\".\n",
    "\n",
    "### Orphan Process\n",
    "#### A process whose parent process no more exists i.e. either finished or terminated without waiting for its child process to terminate. The child process is adopted by init, which periodically checks for orphaned processes and re-parents them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Scheduling Algorithms\n",
    "\n",
    "## Non-preemptive Scheduling Algorithms\n",
    "### 1. First Come First Serve (FCFS)\n",
    "#### job which comes first in the ready queue will get the CPU first. The lesser the arrival time of the job, the sooner will the job get the CPU\n",
    "\n",
    "### 2. Shortest Job First (SJF)\n",
    "####  job with the shortest burst time will get the CPU first. The lesser the burst time, the sooner will the process get the CPU.\n",
    "\n",
    "### 3. Priority Scheduling\n",
    "#### job with the highest priority will get the CPU first. The higher the priority, the sooner will the process get the CPU. if two processes have the same priority, then FCFS is applied.\n",
    "\n",
    "## Preemptive Scheduling Algorithms\n",
    "### 1. Round Robin (RR)\n",
    "#### each process is assigned a fixed time slot in a cyclic way. The process which is currently running is interrupted and the process in the ready queue is given the CPU. The interrupted process is placed at the end of the queue. uses time quantum.\n",
    "\n",
    "### 2. Shortest Remaining Time First (SRTF)\n",
    "####  the process with the shortest remaining time will get the CPU first. The lesser the remaining time, the sooner will the process get the CPU.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deadlock\n",
    "### Deadlock is a situation where each of the computer process waits for a resource which is being assigned to some another process. In this situation, none of the process gets executed since the resource it needs, is held by some other process which is also waiting for some other resource to be released. waiting time can be infinite. Every Deadlock is always a starvation but not every starvation is a deadlock.\n",
    "\n",
    "# Starvation\n",
    "### Starvation is a situation where the low priority process got blocked and the high priority processes proceed. Starvation is a long waiting but not infinite. It occurs due to the uncontrolled priority and resource management.\n",
    "\n",
    "## Conditions Responsible for Deadlock\n",
    "\n",
    "### 1. Mutual Exclusion\n",
    "#### A resource can only be shared in mutually exclusive manner. It implies, if two process cannot use the same resource at the same time. no two processes can exist in the critical section at any given point of time\n",
    "\n",
    "### 2. Hold and Wait\n",
    "#### A process must be holding at least one resource and waiting for another resource that is being held by another process.\n",
    "\n",
    "### 3. No Preemption\n",
    "#### The process which once scheduled will be executed till the completion. No other process can be scheduled by the scheduler meanwhile.\n",
    "\n",
    "### 4. Circular Wait\n",
    "#### There must be a circular chain of processes waiting for each other. Each process is waiting for the next process in the chain to release a resource.\n",
    "\n",
    "## Handling Deadlock\n",
    "### 1. Deadlock Prevention (we have to fail one of the four conditions of deadlock)\n",
    "### 2. Deadlock Avoidance  (OS reviews each allocation so that the allocation doesn't cause the deadlock in the system.)\n",
    "### 3. Deadlock Detection and Recovery (OS detects the deadlock and recovers from it.)\n",
    "### 4. Deadlock Ignorance  (OS ignores the deadlock and continues the execution of the system.)\n",
    "\n",
    "## Deadlock Prevention\n",
    "\n",
    "### 1. Mutual Exclusion -> Spooling\n",
    "#### in spooling, another storage(in device which is getting holds like printer) is used whcih holds process and executes them by FCFS. But we cannot violate mutual exclusion for a process practically.\n",
    "\n",
    "### 2. Hold and Wait \n",
    "####  either you don't hold or you don't wait strategy. implements only if a process declares all the resources initially. \n",
    "\n",
    "### 3. No Preemption    \n",
    "#### if we take the resource away from the process which is causing deadlock then we can prevent deadlock.\n",
    "\n",
    "### 4. Circular Wait\n",
    "####  To violate circular wait, we can assign a priority number to each of the resource. A process can't request for a lesser priority resource. This ensures that not a single process can request a resource which is being utilized by some other process and no cycle will be formed.\n",
    "\n",
    "## Resource Allocation Graph (Deadlock Detection)\n",
    "\n",
    "#### it is a directed graph where each vertex represents a process and each edge represents a resource. The edge from process Pi to process Pj indicates that process Pi is holding a resource that process Pj is waiting for. If there is a cycle in the graph, then there is a possibility of deadlock.\n",
    "\n",
    "## Deadlock Recovery\n",
    "\n",
    "### 1. Kill 1 process or more processes  -> process which has done least amount of work until now.\n",
    "### 2. Rollback to safe state  -> rollback to the state where there was no deadlock.\n",
    "### 3. Preempt the resource ->  snatch one of the resources from the owner of the resource (process) and give it to the other process with the expectation that it will complete the execution and will release this resource sooner. Well, choosing a resource which will be snatched is going to be a bit difficult.\n",
    "\n",
    "## Banker's Algorithm\n",
    "### 1. It is a deadlock avoidance algorithm.\n",
    "### 2. It is a resource allocation and deadlock avoidance algorithm that tests for safety by simulating the allocation for predetermined maximum possible amounts of all resources, then makes a \"s-state\" check to test for possible activities, before deciding whether allocation should be allowed to continue.\n",
    "\n",
    "\n",
    "## Aging \n",
    "### Aging is a technique of gradually increasing the priority of processes that wait in the system for a long time\n",
    "\n",
    "## Livelock\n",
    "### Livelock occurs when two or more processes continually repeat the same interaction in response to changes in the other processes without doing any useful work. These processes are not in the waiting state, and they are running concurrently. This is different from a deadlock because in a deadlock all processes are in the waiting state. \n",
    "\n",
    "\n",
    "## Thrashing\n",
    "### Thrashing is a condition or a situation when the system is spending a major portion of its time servicing the page faults, but the actual processing done is very negligible. \n",
    "#### The basic concept involved is that if a process is allocated too few frames, then there will be too many and too frequent page faults. As a result, no useful work would be done by the CPU and the CPU utilization would fall drastically.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAID\n",
    "###  RAID (redundant array of independent/inexpensive disks) is a way of storing the same data in different places on multiple hard disks or solid-state drives (SSDs) to protect data in the case of a drive failure. There are different RAID levels, however, and not all have the goal of providing redundancy. But OS doesn't know about the RAID. It just sees the disk as a single disk.\n",
    "### RAID is very transparent to the underlying system. This means, to the host system, it appears as a single big disk presenting itself as a linear array of blocks. This allows older technologies to be replaced by RAID without making too many changes in the existing code. \n",
    "## Features of RAID\n",
    "#### 1. Fault Tolerance\n",
    "#### 2. Performance\n",
    "#### 3. Scalability , Availability\n",
    "#### 4.  An improvement in cost-effectiveness because lower-priced disks are used in large numbers.\n",
    "\n",
    "## RAID 0 (only striping)    [strip data -> converting full data to N num. of Blocks]\n",
    "### RAID 0 is taking any number of disks and merging them into one large volume. all data on all disks is lost if any one disk fails cause data is spilled across all disks. still better than having a single disk.\n",
    "\n",
    "## RAID 1  (mirrored disks)\n",
    "### RAID 1 is taking any number of disks and mirroring them. Both disks are store exactly the same data. If one disk fails, the other disk can be used to recover the data. This is the simplest RAID level and is often used as a backup.\n",
    "\n",
    "\n",
    "## RAID 3 (striping with dedicated parity)\n",
    "### RAID 3 is similar to RAID 0, but it adds a dedicated parity disk. The parity disk is used to store parity information for the data on the other disks. This allows for only a single disk failure without losing data. This is a good RAID level for environments where a single disk failure is acceptable (not parity disk). But for every write operation, the parity disk must be updated. This can cause a performance hit.\n",
    "\n",
    "## RAID 5(striped disks with single parity with distribution) (at least 3 disks)\n",
    "### RAID 5 is taking any number of disks and storing data in a striped fashion. The data is striped across all disks and a parity block is stored on one of the disks. If one disk fails, the data can be recovered from the other disks and the parity block. This is the most common RAID level used in enterprise environments. upgrade from RAID 3 cause all parity blocks are distributed across all disks so that if one disk fails, the data can be recovered from the other disks and the parity block. Any one of disk failure is acceptable\n",
    "\n",
    "## RAID 6 (striped disks with double parity with distribution) (at least 4 disks)\n",
    "### similar to RAID 5, but it uses two parity blocks. This allows for two disk failures without losing data. Any two disk failure is acceptable , but it is slower than RAID 5.\n",
    "\n",
    "*Nested RAID*\n",
    "\n",
    "## RAID 0 + 1 (striping and mirroring)  \n",
    "### here data is striped and then mirrored. It provides a good balance between performance(0) and fault tolerance(1).\n",
    "#### e.g.  A -> A1 , A2 ; B -> B1 , B2   then   \n",
    "####       Group1((A1,B1) , (A2,B2))     ,     Group2((A1,B1) , (A2,B2))\n",
    "\n",
    "## RAID 1 + 0 (mirroring and striping)\n",
    "### here data is mirrored and then striped.\n",
    "#### e.g.  Group1((A1,B1) , (A1,B1))  ,       Group2((A2,B2) , (A2,B2))  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source code -> compiler -> Assembler -> Object code -> Linker -> Executable file -> Loader -> Memory\n",
    "\n",
    "# Linker \n",
    "### Linker is a program in a system which helps to link object modules of a program into a single object file. It performs the process of linking .  Linker also links a particular module into system library. It takes object modules from assembler as input and forms an executable file as output for the loader. Linking is performed at both compile time, when the source code is translated into machine code and load time, when the program is loaded into memory by the loader. Linking is performed at the last step in compiling a program.\n",
    "\n",
    "# Loader\n",
    "### It is special program that takes input of executable files from linker, loads it to main memory, and prepares this code for execution by computer. Loader allocates memory space to program. Loader is also responsible for adjusting references which are used within the program.\n",
    "\n",
    "# Assembler\n",
    "### An assembler is a program that takes basic computer instructions and converts them into a pattern of bits that the computer's processor can use to perform its basic operations. The assembler is the first program in the compiler chain. It takes the assembly language code and converts it into machine code. The assembler is also responsible for translating symbolic labels into addresses. \n",
    "\n",
    "# Compiler\n",
    "### A compiler is a program that translates computer code written in one programming language (the source language) into another language (the target language). The most common reason for converting source code from one language to another is to create an executable program. Compilers are also used to translate programs written in high-level languages into lower-level languages(generally assembly) so that they can be run on microprocessors.\n",
    "### E.g. C++ -> C like -> Assembly -> Machine code , Java -> Byte code -> Machine code\n",
    "\n",
    "# Interpreter\n",
    "### An interpreter is a program that directly executes the instructions in a high-level language, without converting it into machine code.It translates only one statement at a time.compile time is less. However, The overall execution time is more.It does not generate any intermediate object code. Hence it is memory efficient. interpreted languages are also called scripting languages.\n",
    "### E.g. Python, Ruby, PHP, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semaphore\n",
    "### Semaphores are integer variables that are used to solve the critical section problem by using two atomic operations, wait and signal that are used for process synchronization.\n",
    "## Types of Semaphore\n",
    "### 1. Binary Semaphore -> uses only 0 and 1 to act as lock and unlock section\n",
    "### 2. Counting Semaphore -> uses a counter to keep track of the number of processes that can access the critical section at a time. If the resources are added, semaphore count automatically incremented and if the resources are removed, the count is decremented.\n",
    "\n",
    "## Uses \n",
    "### 1. Allow only one process to access a shared resource(critical section) at a time.\n",
    "### 2. saves process from deadlock as well as starvation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interrupts\n",
    "\n",
    "### An interrupt is a signal to the processor emitted by hardware or software indicating an event that needs immediate attention. Whenever an interrupt occurs, the controller completes the execution of the current instruction and starts the execution of an Interrupt Service Routine (ISR) or Interrupt Handler."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLI\n",
    "\n",
    "### SH (shell) : Shells may be one of  Korn, C shell, Bourne, Bash, etc.\n",
    "### Bash (“Bourne Again SHell”) : bash is sh, but with more features and better syntax\n",
    "### dash (“Debian Almquist SHell”) : dash is sh, but with fewer features and less syntax\n",
    "### zsh (“Z SHell”) : zsh is sh, but with more features and better syntax\n",
    "### GNOME :  free and open-source desktop environment for Linux and other Unix-like operating system to develop GUI rich applications.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b82bd812b6a37d04ba59de08f4dfa67a262de1c3e27303c0cb0a5b38b381c61f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
